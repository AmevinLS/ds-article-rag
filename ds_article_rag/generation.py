import ollama
from typing import List


def prompt_ollama_with_articles(
    query: str, model: str, articles: List[dict], ollama_host: str
) -> str:
    """
    This function takes a user query, model name, list of articles represented as dictionaries, and Ollama host URL as input.
    It then creates a prompt for Ollama that summarizes the information in the articles and presents it to the user.
    If the articles lack useful information, the prompt suggests improvements to the user's query formulation.

    Args:
        query (str): The user's query to be answered.
        model (str): The name of the Ollama model to be used.
        articles (List[dict]): A list of dictionaries where each dictionary represents an article. 
            The dictionary should have keys 'title' (str) and 'content' (str).
        ollama_host (str): The URL of the Ollama host server.

    Returns:
        str: The response generated by Ollama based on the prompt and user query.
    """
    prompt_system = (
        "Summarize the information to the user's prompt based only on the retrieved documents below. Do not add any external information. "
        "If the articles don't contain much useful information, please say so and suggest improvements to the user's prompt formulation\n\n"
    )
    for i, entry in enumerate(articles):
        prompt_system += f"{i+1}. {entry['title']}\n\n" f"{entry['content']}\n\n"

    client = ollama.Client(host=ollama_host)
    if not any([entry["name"].startwith(model) for entry in client.list()["models"]]):
        client.pull(model)
    ollama_result = client.chat(
        model=model,
        messages=[
            {"role": "system", "content": prompt_system},
            {
                "role": "user",
                "content": query,
            },
        ],
    )
    return ollama_result["message"]["content"]
